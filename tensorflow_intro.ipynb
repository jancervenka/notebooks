{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/get_started/get_started\n",
    "https://www.tensorflow.org/get_started/mnist/beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow core (low level API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two steps:\n",
    "\n",
    "1) building a graph\n",
    "\n",
    "2) running the graph\n",
    "\n",
    "Computational graph is made of nodes each performing a defined operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_9:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n1 = tf.constant(3, dtype = tf.float32) # constant node (no input)\n",
    "n2 = tf.constant(4, dtype = tf.float32)\n",
    "print(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sesh = tf.Session() # session for executing the graph\n",
    "output = sesh.run([n1, n2])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n3': <tf.Tensor 'Add_1:0' shape=() dtype=float32>}\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "n3 = tf.add(n1, n2) # node adding two values together\n",
    "print({'n3' : n3})\n",
    "output_add = sesh.run(n3)\n",
    "print(output_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "[ 3.  4.  9.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32) # placeholder represents a parametrized input, providing an exact value later\n",
    "b = tf.placeholder(tf.float32)\n",
    "n4 = a + b # equivalent to tf.add(a, b)\n",
    "print(sesh.run(n4, {a : 2, b : 2}))\n",
    "print(sesh.run(n4, {a : [2, 2, 6], b : [1, 2, 3]})) # \"vectorized\" input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.  12.  27.]\n"
     ]
    }
   ],
   "source": [
    "n5 = (a + b) * 3\n",
    "print(sesh.run(n5, {a : [2, 2, 6], b : [1, 2, 3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([ .3], dtype = tf.float32) # varibles represents trainable parameters of a graph (weights, biases etc...)\n",
    "b = tf.Variable([-.3], dtype = tf.float32)\n",
    "x = tf.placeholder(tf.float32) # data input\n",
    "lm = w * x + b # linear model\n",
    "\n",
    "# to initiliaze thev ariables, you run:\n",
    "init = tf.global_variables_initializer()\n",
    "sesh.run(init)\n",
    "\n",
    "# to run the model:\n",
    "print(sesh.run(lm, {x : [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32) # desired values\n",
    "\n",
    "# defining loss function (how far the model and y are apart):\n",
    "squared_deltas = tf.square(lm - y) # squared diffenrences\n",
    "loss = tf.reduce_sum(squared_deltas) # sum to get a scalar output value\n",
    "\n",
    "print(sesh.run(loss, {x : [1, 2, 3, 4], y : [0, -1, -2, -3]})) # loss value for y = [0, -1, -2, -3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-1.], dtype=float32), array([ 1.], dtype=float32)]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w_new = tf.assign(w, [-1]) # change the parameters\n",
    "b_new = tf.assign(b, [ 1]) \n",
    "print(sesh.run([w_new, b_new]))\n",
    "print(sesh.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})) # new loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# train to optimize the loss function\n",
    "learning_rate = 0.01\n",
    "# automatically computes the partial derivatives from the model description\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "sesh.run(init) # to reset variables\n",
    "\n",
    "for i in range(1000): # train is connected to the loss, the loss is connected to the lam\n",
    "    sesh.run(train, {x : [1, 2, 3, 4], y : [0, -1, -2, -3]})\n",
    "    \n",
    "print(sesh.run([w, b])) # new parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.estimator (high level API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Jan\\AppData\\Local\\Temp\\tmpg6fuzpmo\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Jan\\\\AppData\\\\Local\\\\Temp\\\\tmpg6fuzpmo', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Jan\\AppData\\Local\\Temp\\tmpg6fuzpmo\\model.ckpt.\n",
      "INFO:tensorflow:loss = 14.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1101.64\n",
      "INFO:tensorflow:loss = 0.158421, step = 101 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1173.29\n",
      "INFO:tensorflow:loss = 0.0259584, step = 201 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1135.54\n",
      "INFO:tensorflow:loss = 0.0107812, step = 301 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1161.86\n",
      "INFO:tensorflow:loss = 0.00192279, step = 401 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1175.55\n",
      "INFO:tensorflow:loss = 0.000100472, step = 501 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1152.8\n",
      "INFO:tensorflow:loss = 7.03774e-05, step = 601 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1134.43\n",
      "INFO:tensorflow:loss = 1.2878e-05, step = 701 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1263.58\n",
      "INFO:tensorflow:loss = 9.37648e-07, step = 801 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1218.67\n",
      "INFO:tensorflow:loss = 3.14597e-07, step = 901 (0.083 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Jan\\AppData\\Local\\Temp\\tmpg6fuzpmo\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.52581e-08.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-14-20:56:41\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jan\\AppData\\Local\\Temp\\tmpg6fuzpmo\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-14-20:56:42\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.38662e-08, global_step = 1000, loss = 5.54647e-08\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-14-20:56:43\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Jan\\AppData\\Local\\Temp\\tmpg6fuzpmo\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-14-20:56:43\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00253582, global_step = 1000, loss = 0.0101433\n",
      "train metrics: {'average_loss': 1.3866169e-08, 'loss': 5.5464675e-08, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0025358244, 'loss': 0.010143298, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# declare list of features, our model has only one numeric feature x, (shape = [1])\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape = [1])]\n",
    "\n",
    "# estimator is an front end interface\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns = feature_columns)\n",
    "\n",
    "# setting up training and evaluation datasets:\n",
    "x_train = np.array([ 1,     2,    3,  4])\n",
    "y_train = np.array([ 0,    -1,   -2, -3])\n",
    "x_eval  = np.array([ 2,     5,    8,  1])\n",
    "y_eval  = np.array([-1.01, -4.1, -7,  0])\n",
    "\n",
    "# define size of the batches and number of batches (epochs)\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, batch_size = 4, \n",
    "                                                                       num_epochs = None, \n",
    "                                                                       shuffle = True)\n",
    "\n",
    "train_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, batch_size = 4, \n",
    "                                                                             num_epochs = 1000, \n",
    "                                                                             shuffle = False)\n",
    "\n",
    "eval_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_eval}, y_eval, batch_size = 4, \n",
    "                                                                          num_epochs = 1000, \n",
    "                                                                          shuffle = False)\n",
    "# train for 1000 steps\n",
    "estimator.train(input_fn=input_fn, steps = 1000)\n",
    "\n",
    "# evaluate the results\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: \" + str(train_metrics))\n",
    "print(\"eval metrics: \" + str(eval_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "784\n",
      "0.151681\n"
     ]
    }
   ],
   "source": [
    "# mnist.train.images (x) 55000 x 784 tensor\n",
    "# mnist.train.labels (y) 55000 x  10 tensor\n",
    "print(mnist.train.labels[5]) # 1 at index 8: digit eight \"one-hot vector\"\n",
    "print(len(mnist.train.images[1])) # 784: 28 by 28 flattened\n",
    "print(mnist.train.images[1].mean()) # mean pixel intensity (1 == 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEX4gKMIPBPX/EhqoeSQulYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24900302e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.resize(mnist.train.images[1], [28, 28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input is an array of any length (None) containing arrays of length 784\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# weights and biases\n",
    "w = tf.Variable(tf.zeros([784, 10])) # 784 weights (for each pixel) for each digit\n",
    "b = tf.Variable(tf.zeros([10])) # one bias for each digiht\n",
    "\n",
    "# wx + b produces [10] 1-D tensor for each image\n",
    "y = tf.nn.softmax(tf.matmul(x, w) + b) # matmul is matrix multiplication\n",
    "\n",
    "# loss function is cross-entropy\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices = [1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sesh = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100) # get new batches for x, and y\n",
    "  sesh.run(train_step, feed_dict = {x : batch_xs, y_ : batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9161\n"
     ]
    }
   ],
   "source": [
    "estimate = tf.argmax(y, 1) # index (digit) with highest probability for each image (argmax alongside dim 1 of tensor y)\n",
    "true = tf.argmax(y_, 1) # true labels\n",
    "correct_prediction = tf.equal(true, estimate)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sesh.run(accuracy, feed_dict = {x : mnist.test.images, y_ : mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
