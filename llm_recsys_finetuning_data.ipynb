{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c3a78f-cfdc-4552-8d8b-a8351451318c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T20:54:50.476777Z",
     "iopub.status.busy": "2024-08-04T20:54:50.475506Z",
     "iopub.status.idle": "2024-08-04T20:54:56.217397Z",
     "shell.execute_reply": "2024-08-04T20:54:56.216203Z",
     "shell.execute_reply.started": "2024-08-04T20:54:50.476725Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    GenerationConfig,\n",
    ")\n",
    "from typing import Iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afa3699-cc53-481c-b470-5b269a0d7283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T20:54:56.220052Z",
     "iopub.status.busy": "2024-08-04T20:54:56.219389Z",
     "iopub.status.idle": "2024-08-04T20:55:10.011761Z",
     "shell.execute_reply": "2024-08-04T20:55:10.010824Z",
     "shell.execute_reply.started": "2024-08-04T20:54:56.220014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.9.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (8.1.7)\n",
      "Collecting dm-tree (from tensorflow-datasets)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting immutabledict (from tensorflow-datasets)\n",
      "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.26.3)\n",
      "Collecting promise (from tensorflow-datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.23.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (5.9.8)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (15.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.31.0)\n",
      "Collecting simple-parsing (from tensorflow-datasets)\n",
      "  Downloading simple_parsing-0.1.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets)\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.4.0)\n",
      "Collecting toml (from tensorflow-datasets)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.66.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.14.1)\n",
      "Collecting array-record>=0.5.0 (from tensorflow-datasets)\n",
      "  Downloading array_record-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (699 bytes)\n",
      "Collecting etils>=1.9.1 (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
      "  Downloading etils-1.9.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2023.6.0)\n",
      "Collecting importlib_resources (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in /usr/lib/python3/dist-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2020.6.20)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Collecting docstring-parser~=0.15 (from simple-parsing->tensorflow-datasets)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow-datasets)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf>=3.20 (from tensorflow-datasets)\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Downloading tensorflow_datasets-4.9.6-py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading array_record-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading etils-1.9.2-py3-none-any.whl (161 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading simple_parsing-0.1.5-py3-none-any.whl (113 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
      "Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=59e6b77d332437a756c8c37078213c9f1e5a6396dad3532d06067c749506037c\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/74/b1/9b54c896b8d9409e9268329d4d45ede8a8040abe91c8879932\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, toml, protobuf, promise, importlib_resources, immutabledict, etils, docstring-parser, simple-parsing, googleapis-common-protos, tensorflow-metadata, array-record, tensorflow-datasets\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.4\n",
      "    Uninstalling protobuf-4.23.4:\n",
      "      Successfully uninstalled protobuf-4.23.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed array-record-0.5.1 dm-tree-0.1.8 docstring-parser-0.16 etils-1.9.2 googleapis-common-protos-1.63.2 immutabledict-4.2.0 importlib_resources-6.4.0 promise-2.3 protobuf-4.25.4 simple-parsing-0.1.5 tensorflow-datasets-4.9.6 tensorflow-metadata-1.15.0 toml-0.10.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets\n",
    "import tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18300c7a-ded7-49da-a296-23b89dcad2d6",
   "metadata": {},
   "source": [
    "## First Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "391a07de-1531-4f33-be40-a35467d8c7fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T21:28:50.758712Z",
     "iopub.status.busy": "2024-08-04T21:28:50.757846Z",
     "iopub.status.idle": "2024-08-04T21:29:02.202983Z",
     "shell.execute_reply": "2024-08-04T21:29:02.201856Z",
     "shell.execute_reply.started": "2024-08-04T21:28:50.758676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663fadbdc98141f99ae19614fdc59205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3a438e3df545738a1e280b586ef957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758b26f63ac349efa65d8b34d9d003c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab23e699c7924fb886fa65c381c1dfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fbd48a539a4950a413c2e206611f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e89b1a01b04e60bc378eb4fc9669c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/724 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4da469926544bf9ed50fc31a9cde98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a5196569534a328486b81a48956760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-135M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "# for fp16 use `torch_dtype=torch.float16` instead\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.bfloat16).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44589c9f-9504-4f53-abf5-9409a594b206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T21:29:02.206983Z",
     "iopub.status.busy": "2024-08-04T21:29:02.206223Z",
     "iopub.status.idle": "2024-08-04T21:29:15.840005Z",
     "shell.execute_reply": "2024-08-04T21:29:15.838619Z",
     "shell.execute_reply.started": "2024-08-04T21:29:02.206958Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! How are you?\n",
      "\n",
      "Alice: I'm fine, thanks. I'm trying to learn about the history of the United States. Do you know anything about the American Revolution?\n",
      "\n",
      "Bob: Sure, Alice! The American Revolution was a time when the thirteen American colonies decided to break away from Great Britain and form their own country. They fought against British rule for many years.\n",
      "\n",
      "Alice: That sounds like a long time ago! Why did they want to do that?\n",
      "\n",
      "Bob: Well, there were many reasons. One reason was that the British had taken control of their land and made them pay taxes. Another reason was that the colonists wanted more freedom and self-governance.\n",
      "\n",
      "Alice: Oh, I see. So, they didn't want to be ruled by the British?\n",
      "\n",
      "Bob: Exactly! And they also believed that they had a right to govern themselves. This idea is called the \"American Revolution.\"\n",
      "\n",
      "Alice: Wow, that\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    max_length=200,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "inputs = tokenizer.encode(\"Hi! How are you?\", return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "012795dc-c628-48fe-b45a-976686305bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T21:29:24.719839Z",
     "iopub.status.busy": "2024-08-04T21:29:24.719311Z",
     "iopub.status.idle": "2024-08-04T21:29:24.732595Z",
     "shell.execute_reply": "2024-08-04T21:29:24.730876Z",
     "shell.execute_reply.started": "2024-08-04T21:29:24.719800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 284.76 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory footprint: {model.get_memory_footprint() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7be6e-da72-42d0-96df-05616596ed39",
   "metadata": {},
   "source": [
    "## Training Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "78375807-2298-4b70-9786-5f99cd1be238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T21:33:50.960265Z",
     "iopub.status.busy": "2024-08-04T21:33:50.959895Z",
     "iopub.status.idle": "2024-08-04T21:33:50.968144Z",
     "shell.execute_reply": "2024-08-04T21:33:50.966890Z",
     "shell.execute_reply.started": "2024-08-04T21:33:50.960228Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(split: str) -> Dataset:\n",
    "    ratings = tensorflow_datasets.load(\"movielens/100k-ratings\", split=split)\n",
    "    materialized_ratings = pd.DataFrame(ratings.as_numpy_iterator())[[\"user_id\", \"movie_id\"]]\n",
    "    for col in materialized_ratings:\n",
    "        materialized_ratings[col] = materialized_ratings[col].str.decode(\"utf8\")\n",
    "\n",
    "    agg_ratings = (\n",
    "        materialized_ratings\n",
    "        .groupby(\"user_id\")\n",
    "        .agg(movie_ids=(\"movie_id\", lambda x: \",\".join(x)))\n",
    "        .reset_index()\n",
    "        .to_dict(\"records\")\n",
    "    )\n",
    "    \n",
    "    formatted_agg_ratings = [\n",
    "        {\"input\": f\"user_id: {u['user_id']}, movie_ids: {u['movie_ids']}\"}\n",
    "        for u in agg_ratings\n",
    "    ]\n",
    "\n",
    "    return Dataset.from_list(formatted_agg_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "af99df64-0270-4845-9320-4f493b083d9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T21:50:03.463303Z",
     "iopub.status.busy": "2024-08-04T21:50:03.462880Z",
     "iopub.status.idle": "2024-08-04T21:50:59.507408Z",
     "shell.execute_reply": "2024-08-04T21:50:59.505695Z",
     "shell.execute_reply.started": "2024-08-04T21:50:03.463269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df015ea1a984db58053379539245bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/943 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_ratings = create_dataset(\"train\")\n",
    "# https://huggingface.co/docs/transformers/pad_truncation\n",
    "# train_tokenized_ratings = tokenizer(train_ratings[\"input\"], padding=\"longest\")\n",
    "train_tokenized_ratings = train_ratings.map(\n",
    "    lambda x: tokenizer(x[\"input\"], padding=\"max_length\", max_length=3110),\n",
    "    batched=True,\n",
    "    remove_columns=[\"input\"],\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec353d54-a86b-4cae-b8a3-5fb681819e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T20:28:10.590282Z",
     "iopub.status.busy": "2024-08-02T20:28:10.589243Z",
     "iopub.status.idle": "2024-08-02T20:28:10.594248Z",
     "shell.execute_reply": "2024-08-02T20:28:10.593399Z",
     "shell.execute_reply.started": "2024-08-02T20:28:10.590241Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_tokenized_ratings= train_tokenized_ratings.add_column(\n",
    "#     \"labels\",\n",
    "#     train_tokenized_ratings[\"input_ids\"].copy()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "85d5c067-f347-49fa-9c0c-0dcd0fd6e66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T21:51:43.093484Z",
     "iopub.status.busy": "2024-08-04T21:51:43.093010Z",
     "iopub.status.idle": "2024-08-04T21:51:43.104430Z",
     "shell.execute_reply": "2024-08-04T21:51:43.101810Z",
     "shell.execute_reply.started": "2024-08-04T21:51:43.093447Z"
    }
   },
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    block_size = 128\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5ddc764b-0334-4863-8bfa-446e130d001c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T21:51:46.559656Z",
     "iopub.status.busy": "2024-08-04T21:51:46.559153Z",
     "iopub.status.idle": "2024-08-04T21:52:08.711918Z",
     "shell.execute_reply": "2024-08-04T21:52:08.710512Z",
     "shell.execute_reply.started": "2024-08-04T21:51:46.559593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4a87fb2c2f4c93ac7b2c7c919f00f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/943 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_grouped_tokenized_ratings = train_tokenized_ratings.map(group_texts, batched=True,) #num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ed6b3ec8-a214-444b-a942-271ff922431d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T21:52:14.689086Z",
     "iopub.status.busy": "2024-08-04T21:52:14.688755Z",
     "iopub.status.idle": "2024-08-04T21:52:14.785541Z",
     "shell.execute_reply": "2024-08-04T21:52:14.783968Z",
     "shell.execute_reply.started": "2024-08-04T21:52:14.689061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab9a7ed0fdc41308894df31e6fc863d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/22911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(\"train_grouped_tokenized_ratings\", exist_ok=True)\n",
    "train_grouped_tokenized_ratings.save_to_disk(\"train_grouped_tokenized_ratings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
